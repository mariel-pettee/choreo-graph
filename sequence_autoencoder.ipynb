{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functions.seq_autoencoder import *\n",
    "setup_gpus()\n",
    "ds_all, ds_all_centered, datasets, datasets_centered, ds_counts = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animate the real data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particularly cool starting frame numbers to look at:\n",
    "- 11910\n",
    "- 9259\n",
    "- 21755\n",
    "- 2207\n",
    "- 37067\n",
    "- 13443\n",
    "- 28840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 128\n",
    "index_start = 11910\n",
    "# index_start = np.random.randint(0,len(ds_all_centered)-seq_len)\n",
    "print(\"Seeding with frame {}\".format(index_start))\n",
    "xtest = ds_all_centered[index_start:index_start+seq_len]\n",
    "animation = animate_stick(xtest, \n",
    "                          figsize=(10,8), \n",
    "                          cmap='inferno', \n",
    "                          cloud=False\n",
    "                         )\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained model and generate new movements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len      = 128\n",
    "latent_dim   = 256\n",
    "n_layers     = 3 #2\n",
    "n_units      = 384 \n",
    "use_dense    = True\n",
    "kl_weight    = 1 \n",
    "resolution   = 3e-1 \n",
    "lr           = 3e-4\n",
    "do_rotations = True\n",
    "extrap_len   = seq_len//2\n",
    "\n",
    "encoder, decoder, auto, mk_continuizer = mk_seq_ae(ds_all, seq_len=seq_len, latent_dim=latent_dim,\n",
    "                                   n_units=n_units, n_layers=n_layers,\n",
    "                                  use_dense=use_dense, kl_weight=kl_weight,\n",
    "                                  resolution=resolution, do_rotations=do_rotations, extrap_len=extrap_len)\n",
    "continuizer = mk_continuizer(1)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "auto.summary()\n",
    "\n",
    "K.set_value(auto.optimizer.lr, lr)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_encoder.h5')\n",
    "decoder.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_decoder.h5')\n",
    "auto.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_autoencoder.h5')\n",
    "auto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder (blue) tries to imitate the real Mariel (black):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_start = np.random.randint(0,len(ds_all_centered)-seq_len)\n",
    "print(\"Seeding with frame {}\".format(index_start))\n",
    "xtest = ds_all_centered[index_start:index_start+seq_len]\n",
    "xpred = auto.predict(np.expand_dims(xtest,axis=0))[0]\n",
    "animation = animate_stick(xtest,ghost=xpred, dot_alpha=0.7, ghost_shift=0.2, figsize=(12,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a random 2D slice of the 256-dimensional latent space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill an array of len(number_of_points) with full 256-dimensional latent space points for number_of_points sequential sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "z_points = []\n",
    "indices = []\n",
    "\n",
    "number_of_points = 50\n",
    "\n",
    "# index = 0\n",
    "index = np.random.randint(0,len(ds_all_centered)-seq_len)  # random place to start in the real data\n",
    "\n",
    "while(n < number_of_points):\n",
    "    indices.append(index)\n",
    "    index += 1\n",
    "    xtest = ds_all_centered[index:index+seq_len]\n",
    "    _, ztest, _ = encoder.predict(np.expand_dims(xtest,axis=0))\n",
    "    z_points.append(ztest)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a random direction in the latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat = np.random.randint(0,256)\n",
    "y_hat = np.random.randint(0,256)\n",
    "z_hat = np.random.randint(0,256)\n",
    "    \n",
    "print(\"Latent space direction: ({},{},{})\".format(x_hat,y_hat,z_hat))\n",
    "x = np.zeros(number_of_points)\n",
    "y = np.zeros(number_of_points)\n",
    "z = np.zeros(number_of_points)\n",
    "\n",
    "for i in range(len(z_points)):\n",
    "    x[i] = z_points[i][0,x_hat]\n",
    "    y[i] = z_points[i][0,y_hat]\n",
    "    z[i] = z_points[i][0,z_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now travel through the latent space in this direction and plot what you find:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "plt.figure(figsize=(10,8))    \n",
    "# 2D\n",
    "plt.scatter(x,y,c=np.arange(number_of_points),cmap='viridis')\n",
    "\n",
    "# draw a colormapped line through the scatter points\n",
    "points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "lc = LineCollection(segments, cmap=plt.get_cmap('viridis'),\n",
    "    norm=plt.Normalize(0, number_of_points))\n",
    "lc.set_array(np.arange(number_of_points))\n",
    "lc.set_linewidth(3)\n",
    "plt.gca().add_collection(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm    \n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "\n",
    "fig = plt.figure(figsize=(20,16))\n",
    "ax = fig.add_subplot(111, projection='3d')   \n",
    "\n",
    "ax.scatter(x,y,z,\n",
    "           marker='o',\n",
    "            c=np.arange(number_of_points),\n",
    "            cmap='viridis',\n",
    "           alpha=1,\n",
    "           )\n",
    "\n",
    "# draw a colormapped line through the scatter points\n",
    "points = np.array([x, y, z]).T.reshape(-1, 1, 3)\n",
    "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "lc = Line3DCollection(segments, cmap=plt.get_cmap('viridis'),\n",
    "    norm=plt.Normalize(0, number_of_points))\n",
    "lc.set_array(np.arange(number_of_points))\n",
    "lc.set_linewidth(5)\n",
    "plt.gca().add_collection(lc)\n",
    "\n",
    "\n",
    "# shadows on walls\n",
    "# ax.plot(x, z, 'r+', zdir='y', zs=1.5)\n",
    "# ax.plot(y, z, 'g+', zdir='x', zs=-0.5)\n",
    "ax.plot(x, y, color='grey',linestyle='--', zdir='z', \n",
    "        zs=np.min(z)\n",
    "       )\n",
    "# ax.set_zlim([-1, 0.2])\n",
    "\n",
    "\n",
    "### to match up with 2D:\n",
    "# angle=270\n",
    "# ax.view_init(90, angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try some variations by adding noise to latent space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ztest, _ = encoder.predict(np.expand_dims(xtest,axis=0))\n",
    "xproj = decoder.predict(ztest + np.random.normal(0,0.25,latent_dim))[0]\n",
    "animation = animate_stick(xtest, ghost=xproj, ghost_shift=0.2, figsize=(12,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xproj = decoder.predict(ztest + np.random.normal(0,0.5,latent_dim))[0]\n",
    "animation = animate_stick(xtest, ghost=xproj, ghost_shift=0.2, figsize=(12,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xproj = decoder.predict(ztest + np.random.normal(0,1,latent_dim))[0]\n",
    "animation = animate_stick(xtest, ghost=xproj, ghost_shift=0.2, figsize=(12,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sigma = $big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xproj = decoder.predict(ztest + np.random.normal(0,1.5,latent_dim))[0]\n",
    "animation = animate_stick(xtest, ghost=xproj, ghost_shift=0.2, figsize=(12,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try sampling randomly from the latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "\n",
    "animation = animate_stick(xgen, \n",
    "                          cmap='inferno', \n",
    "                          figsize=(12,8),\n",
    "                          cloud=False,\n",
    "                         )\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the animation as a movie with a transparent background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = animate_stick(xgen, \n",
    "                          figsize=(12,8), \n",
    "                          cmap='inferno', \n",
    "                          cloud=True\n",
    "                         )\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index = save_index + 1\n",
    "\n",
    "animation.save('gen_transparent_alpha03_'+str(save_index)+'.mov', codec=\"png\",\n",
    "         dpi=100, bitrate=-1, \n",
    "         savefig_kwargs={'transparent': True, 'facecolor': 'none'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressively larger-sigma variations on the same sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_increase = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "animation = animate_stick(xgen, cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = sigma + sigma_increase\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "animation = animate_stick(xgen, cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = sigma + sigma_increase\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "animation = animate_stick(xgen, cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = sigma + sigma_increase\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "animation = animate_stick(xgen, cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large sigma only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 5\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "animation = animate_stick(xgen, cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len      = 128\n",
    "latent_dim   = 256\n",
    "n_layers     = 3 #2\n",
    "n_units      = 384 #256\n",
    "use_dense    = True\n",
    "kl_weight    = 1 #1e-2\n",
    "resolution   = 3e-1 #1e-2\n",
    "lr           = 3e-4\n",
    "do_rotations = True\n",
    "extrap_len   = seq_len//2\n",
    "#do_shift     = False\n",
    "#do_inplace   = False\n",
    "\n",
    "encoder, decoder, auto, mk_continuizer = mk_seq_ae(ds_all, seq_len=seq_len, latent_dim=latent_dim,\n",
    "                                   n_units=n_units, n_layers=n_layers,\n",
    "                                  use_dense=use_dense, kl_weight=kl_weight,\n",
    "                                  resolution=resolution, do_rotations=do_rotations, extrap_len=extrap_len)\n",
    "continuizer = mk_continuizer(1)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "auto.summary()\n",
    "\n",
    "K.set_value(auto.optimizer.lr, lr)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture\n",
    "with open('vae_lstm_enc_model.json', 'w') as f:\n",
    "    f.write(encoder.to_json())\n",
    "with open('vae_lstm_dec_model.json', 'w') as f:\n",
    "    f.write(decoder.to_json())\n",
    "with open('vae_lstm_auto_model.json', 'w') as f:\n",
    "    f.write(auto.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "lr = 1e-5\n",
    "kl_weight = 2e-4  # range from 1e-5 to 1e-2\n",
    "nstep = sum([c-seq_len for c in ds_counts])//batch_size\n",
    "\n",
    "K.set_value(auto.optimizer.lr, lr) \n",
    "K.set_value(auto.hp_kl_weight, kl_weight)\n",
    "\n",
    "try:\n",
    "    auto.fit_generator(gen_batches_safe(ds_all_centered, ds_counts, batch_size, seq_len),steps_per_epoch=nstep, epochs=epochs, verbose=1)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted.\")\n",
    "\n",
    "print(\"Updating loss history\")\n",
    "loss_history.extend(auto.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nskip = 0\n",
    "xepochs = np.arange(len(loss_history))+1\n",
    "plt.plot(xepochs[nskip:], loss_history[nskip:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights:\n",
    "encoder.save_weights('learning_rate_'+lr+'vae_lstm_enc_weights.h5')\n",
    "decoder.save_weights('learning_rate_'+lr+'vae_lstm_dec_weights.h5')\n",
    "auto.save_weights('learning_rate_'+lr+'vae_lstm_auto_weights.h5')\n",
    "\n",
    "# Save model: \n",
    "encoder.save('learning_rate_'+lr+'vae_lstm_enc_model.h5')\n",
    "decoder.save('learning_rate_'+lr+'vae_lstm_dec_model.h5')\n",
    "auto.save('learning_rate_'+lr+'vae_lstm_auto_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo",
   "language": "python",
   "name": "choreo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
