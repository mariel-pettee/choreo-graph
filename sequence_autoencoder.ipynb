{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functions.chase import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all, ds_all_centered, datasets, datasets_centered, ds_counts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100\n",
    "index_start = np.random.randint(0,len(ds_all_centered)-seq_len)\n",
    "print(\"Seeding with frame {}\".format(index_start))\n",
    "xtest = ds_all[index_start:index_start+seq_len]\n",
    "HTML(animate_stick(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seq_len      = 128\n",
    "latent_dim   = 256\n",
    "n_layers     = 3 #2\n",
    "n_units      = 384 #256\n",
    "use_dense    = True\n",
    "kl_weight    = 1 #1e-2\n",
    "resolution   = 3e-1 #1e-2\n",
    "lr           = 3e-4\n",
    "do_rotations = True\n",
    "extrap_len   = seq_len//2\n",
    "#do_shift     = False\n",
    "#do_inplace   = False\n",
    "\n",
    "encoder, decoder, auto, mk_continuizer = mk_seq_ae(ds_all, seq_len=seq_len, latent_dim=latent_dim,\n",
    "                                   n_units=n_units, n_layers=n_layers,\n",
    "                                  use_dense=use_dense, kl_weight=kl_weight,\n",
    "                                  resolution=resolution, do_rotations=do_rotations, extrap_len=extrap_len)\n",
    "continuizer = mk_continuizer(1)\n",
    "encoder.summary()\n",
    "decoder.summary()\n",
    "auto.summary()\n",
    "\n",
    "K.set_value(auto.optimizer.lr, lr)\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture\n",
    "with open('vae_lstm_enc_model.json', 'w') as f:\n",
    "    f.write(encoder.to_json())\n",
    "with open('vae_lstm_dec_model.json', 'w') as f:\n",
    "    f.write(decoder.to_json())\n",
    "with open('vae_lstm_auto_model.json', 'w') as f:\n",
    "    f.write(auto.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 #32\n",
    "epochs = 10\n",
    "lr = 1e-5\n",
    "kl_weight = 2e-4  # range from 1e-5 to 1e-2\n",
    "nstep = sum([c-seq_len for c in ds_counts])//batch_size\n",
    "\n",
    "K.set_value(auto.optimizer.lr, lr) \n",
    "K.set_value(auto.hp_kl_weight, kl_weight)\n",
    "\n",
    "try:\n",
    "    auto.fit_generator(gen_batches_safe(ds_all_centered, ds_counts, batch_size, seq_len),steps_per_epoch=nstep, epochs=epochs, verbose=1)\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted.\")\n",
    "\n",
    "print(\"Updating loss history\")\n",
    "loss_history.extend(auto.history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nskip = 0\n",
    "xepochs = np.arange(len(loss_history))+1\n",
    "plt.plot(xepochs[nskip:], loss_history[nskip:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights:\n",
    "encoder.save_weights('learning_rate_'+lr+'vae_lstm_enc_weights.h5')\n",
    "decoder.save_weights('learning_rate_'+lr+'vae_lstm_dec_weights.h5')\n",
    "auto.save_weights('learning_rate_'+lr+'vae_lstm_auto_weights.h5')\n",
    "\n",
    "# Save model: \n",
    "encoder.save('learning_rate_'+lr+'vae_lstm_enc_model.h5')\n",
    "decoder.save('learning_rate_'+lr+'vae_lstm_dec_model.h5')\n",
    "auto.save('learning_rate_'+lr+'vae_lstm_auto_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check autoencoder reconstruction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_encoder.h5')\n",
    "decoder.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_decoder.h5')\n",
    "auto.load_weights('weights/checkpoint_weights_vae_lstm_continued2_lr_0.001_autoencoder.h5')\n",
    "auto.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoencoder (red) tries to imitate the real Mariel (pink):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_start = np.random.randint(0,len(ds_all_centered)-seq_len)\n",
    "index_start = 9259\n",
    "print(\"Seeding with frame {}\".format(index_start))\n",
    "xtest = ds_all_centered[index_start:index_start+seq_len]\n",
    "xpred = auto.predict(np.expand_dims(xtest,axis=0))[0]\n",
    "HTML(animate_stick(xtest,ghost=xpred, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try some variations by adding noise to latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ztest, _ = encoder.predict(np.expand_dims(xtest,axis=0))\n",
    "xproj = decoder.predict(ztest + np.random.normal(0,0.25,latent_dim))[0]\n",
    "HTML(animate_stick(xtest, ghost=xproj, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ztest, _ = encoder.predict(np.expand_dims(xtest,axis=0))\n",
    "xproj = decoder.predict(ztest + np.random.normal(0,0.5,latent_dim))[0]\n",
    "HTML(animate_stick(xtest, ghost=xproj, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ztest, _ = encoder.predict(np.expand_dims(xtest,axis=0))\n",
    "xproj = decoder.predict(ztest + np.random.normal(0,1,latent_dim))[0]\n",
    "HTML(animate_stick(xtest, ghost=xproj, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try sampling randomly from the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1\n",
    "\n",
    "xgen = decoder.predict(np.random.normal(0,sigma,(1,latent_dim)))[0]\n",
    "HTML(animate_stick(xgen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo",
   "language": "python",
   "name": "choreo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
