{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functions.functions import *\n",
    "from functions.plotting import *\n",
    "from functions.autoencoder import *\n",
    "from functions.mdn import *\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "import livelossplot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from itertools import combinations\n",
    "import matplotlib\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/gpfs/loomis/project/hep/demers/mnp3/conda_envs/choreo/bin/ffmpeg' # for using html5 video in Jupyter notebook\n",
    "print(matplotlib.animation.writers.list()) # check that ffmpeg is loaded. if it's not there, use .to_jshtml() instead of .to_html5_video()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('rnn_data/mariel_*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame = np.random.randint(0,data.full.X.shape[1]-50)\n",
    "print(\"Starting from frame {}...\".format(frame))\n",
    "\n",
    "HTML(animate(data.full.X[:,frame:,:], frames=100))\n",
    "# HTML(animate(data.selected.X[:,frame:,:], frames=100, edges=data.selected.edges, colors='black'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the autoencoder for poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = data.selected.X    # 15 joints\n",
    "X_train = data.full.X[:,:int(data.full.X.shape[1]*.8),:]    # 53 joints (80% train)\n",
    "X_test = data.full.X[:,int(data.full.X.shape[1]*.8):,:]    # 53 joints (20% test)\n",
    "print(\"Training set size: {}\".format(X_train.shape))\n",
    "print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train without adding random (x,y) offsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae_nooffset = Autoencoder(n_verts=X_train.shape[0], latent_dim=2, n_layers=2, n_units=64, relu=True, dropout=False, add_random_offsets=False)\n",
    "ae_nooffset.model.summary()\n",
    "X_T = X_train.transpose((1,0,2))\n",
    "ae_nooffset.model.fit(X_T, X_T, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data in blue, autoencoded predictions in orange (we want these to be very similar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 100\n",
    "frame = np.random.randint(0,X_test.shape[1]-n_frames)\n",
    "print(\"Seeding with frame {}\".format(frame))\n",
    "nooffset_predictions = ae_nooffset.get_predictions(X_test, start_frame=frame, n_frames=n_frames)\n",
    "HTML(animate_ghost(X_test[:,frame:,:], nooffset_predictions, frames=n_frames, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.predict(X_test.transpose((1,0,2))).shape\n",
    "# print(X_test_encoded.shape)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.scatter(X_test_encoded[:, 0], X_test_encoded[:, 1], c=np.arange(len(X_test)))\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with adding random (x,y) offsets to the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae_withoffset = Autoencoder(n_verts=X_train.shape[0], latent_dim=32, n_layers=2, n_units=64, relu=True, dropout=False, add_random_offsets=False)\n",
    "ae_withoffset.model.summary()\n",
    "X_T = X_train.transpose((1,0,2))\n",
    "ae_withoffset.model.fit(X_T, X_T, batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data in blue, autoencoded predictions in orange (we want these to be very similar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_frames = 100\n",
    "frame = np.random.randint(0,X_test.shape[1]-n_frames)\n",
    "print(\"Seeding with frame {}\".format(frame)) \n",
    "withoffset_predictions = ae_withoffset.get_predictions(X_test, start_frame=frame, n_frames=n_frames)\n",
    "HTML(animate_ghost(X_test[:,frame:,:], withoffset_predictions, frames=n_frames, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare predictions with and without (x,y) offsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 100\n",
    "frame = np.random.randint(0,X_test.shape[1]-n_frames)\n",
    "print(\"Seeding with frame {}\".format(frame)) \n",
    "nooffset_predictions = ae_nooffset.get_predictions(X_test, start_frame=frame, n_frames=n_frames)\n",
    "withoffset_predictions = ae_withoffset.get_predictions(X_test, start_frame=frame, n_frames=n_frames)\n",
    "HTML(animate_ghost(nooffset_predictions, withoffset_predictions, frames=n_frames, ghost_shift=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pose(x, ax=None, lim=(-0.5, 0.5), center=False, colors=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = p3.Axes3D(fig)\n",
    "    if center:\n",
    "        x = x-x.mean(axis=0)\n",
    "    ax.set_xlim(*lim)\n",
    "    ax.set_ylim(*lim)\n",
    "    ax.set_zlim(*lim)\n",
    "    ax.scatter(x[:,0], x[:,1], x[:,2], c=colors)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stick(x, edges, ax=None, fig=None, subplot=None, lim=(-0.5,0.5), center=False, colors=None):\n",
    "    if subplot is not None:\n",
    "        if fig is None:\n",
    "            fig = plt.figure()\n",
    "        ax = fig.add_subplot(*subplot, projection='3d')\n",
    "    if ax is None:\n",
    "        if fig is None:\n",
    "            fig = plt.figure()\n",
    "        ax = p3.Axes3D(fig)\n",
    "    if center:\n",
    "        x = x-x.mean(axis=0)\n",
    "    ax.set_xlim(*lim)\n",
    "    ax.set_ylim(*lim)\n",
    "    ax.set_zlim(*lim)\n",
    "    #ax.scatter(x[:,0], x[:,1], x[:,2])\n",
    "    for ie,e in enumerate(edges):\n",
    "        if colors is not None:\n",
    "            c = colors[ie]\n",
    "        else:\n",
    "            c = None\n",
    "        ax.plot(np.linspace(x[e[0],0],x[e[1],0],10),np.linspace(x[e[0],1],x[e[1],1],10),np.linspace(x[e[0],2],x[e[1],2],10), color=c)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "# Simple autoencoder to learn single-frame poses\n",
    "# Parameters:\n",
    "#   X: input dataset (used to determine shapes)\n",
    "#   n_units: A tuple of 1 or more integers indicating the number of Dense layer units for each dense layer desired.\n",
    "#   add_noise: if True, add unit gaussian noise to each of the encoded layer outputs.\n",
    "#\n",
    "# The returned model requires no target values during training/evaluation\n",
    "# (since the target values are the same as the inputs).\n",
    "def mk_pose_ae(X, n_units=(32,), add_noise=True):\n",
    "    K.clear_session()\n",
    "    \n",
    "    # Define an activation for hidden layers\n",
    "    def s(L):\n",
    "        return layers.PReLU()(L)\n",
    "    \n",
    "    H = encoder_input = layers.Input((X.shape[1], X.shape[2]))\n",
    "    \n",
    "    # Shift the (x,y) values of the input so that it is centered at zero.\n",
    "    # The z-coordinate is left unchanged.\n",
    "    offsets = layers.Lambda(lambda x: K.constant([[[1,1,0]]])*K.mean(x,axis=1,keepdims=True))(encoder_input)\n",
    "    H = layers.Subtract()([H, offsets])\n",
    "    \n",
    "    # Flatten vertices before feeding into dense networks.\n",
    "    H = layers.Reshape((X.shape[1]*X.shape[2],))(H)\n",
    "    \n",
    "    # Create the specified number and size of Dense layers.\n",
    "    for nu in n_units:\n",
    "        H = layers.Dense(nu)(H)\n",
    "        H = s(H)\n",
    "    \n",
    "    # add unit gaussian noise to the latent space, if requested.\n",
    "    if add_noise:\n",
    "        R = K.random_normal(K.shape(H), 0, 1)\n",
    "        H = layers.Lambda(lambda x: x+R)(H)\n",
    "    \n",
    "    # Decoder layers progressively scale the latent space back to\n",
    "    # original input size.\n",
    "    for nu in n_units[::-1][1:]:\n",
    "        H = layers.Dense(nu)(H)\n",
    "        H = s(H)\n",
    "    \n",
    "    # Final dense output layer with tanh activation for (-1,1) range.\n",
    "    H = layers.Dense((X.shape[1]*X.shape[2]), activation='tanh')(H)\n",
    "    H = layers.Reshape((X.shape[1],X.shape[2]))(H)\n",
    "    \n",
    "    # restore the subtracted (x,y) offset before outputting\n",
    "    H = layers.Add()([H, offsets])\n",
    "    decoder_output = H\n",
    "    \n",
    "    autoencoder = Model(encoder_input, decoder_output)\n",
    "    \n",
    "    # Define the autoencoder loss as the pointwise mean squared error of the\n",
    "    # output relative to the input.\n",
    "    ae_loss = K.mean(K.sum(K.square(decoder_output-encoder_input), axis=-1))\n",
    "    autoencoder.add_loss(ae_loss)\n",
    "    \n",
    "    # compile model without target y values (loss is defined by input and output layers only).\n",
    "    autoencoder.compile(optimizer='adam')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate network with whatever parameters you like!\n",
    "\n",
    "n_units = (32,)\n",
    "add_noise = True\n",
    "\n",
    "auto = mk_pose_ae(X_train.transpose((1,0,2)), n_units=n_units, add_noise=add_noise)\n",
    "auto.summary()\n",
    "\n",
    "# these will get populated after each call to fit() by the values in the\n",
    "# built-in History callback.\n",
    "losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training parameters and fit the model.\n",
    "# Note: subjectively, it seems that a loss of 2e-3 looks fairly convincing.\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "learning_rate = 3e-4\n",
    "\n",
    "\n",
    "K.set_value(auto.optimizer.lr, learning_rate)\n",
    "\n",
    "auto.fit(X_train.transpose((1,0,2)), None, validation_data=(X_test.transpose((1,0,2)), None), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "losses.extend(auto.history.history['loss'])\n",
    "val_losses.extend(auto.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses and some example auto-encoded poses from the validation set\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "n_sample = 1\n",
    "itest = np.random.randint(0,X_test.shape[1],n_sample)\n",
    "print(\"Using frame # {}\".format(itest))\n",
    "xtest = X_test.transpose((1,0,2))[itest]\n",
    "ytest = auto.predict(xtest)\n",
    "for i in range(n_sample):\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    plt.suptitle(\"Validation frame %d\"% itest[i])\n",
    "    plot_pose(xtest[i]-xtest[i].mean(axis=0), center=True, colors='magenta')\n",
    "    plot_pose(ytest[i]-ytest[i].mean(axis=0), center=True, colors='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo",
   "language": "python",
   "name": "choreo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
