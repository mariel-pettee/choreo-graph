{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, SubsetRandomSampler, SequentialSampler\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "\n",
    "import networkx as nx # for visualizing graphs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "from torchsummary import summary\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from functions.load_data import MarielDataset, edges\n",
    "from functions.functions import *\n",
    "from functions.modules import *\n",
    "from functions.seq_autoencoder import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_len = 49\n",
    "predicted_timesteps = 0\n",
    "data = MarielDataset(seq_len=seq_len, reduced_joints=False, predicted_timesteps=predicted_timesteps, no_overlap=False)\n",
    "\n",
    "train_indices = np.arange(int(0.7*len(data))) # 70% split for training data, no shuffle\n",
    "val_indices = np.arange(int(0.7*len(data)),int(0.85*len(data))) # next 15% on validation\n",
    "test_indices = np.arange(int(0.85*len(data)), len(data)) # last 15% on test\n",
    "\n",
    "dataloader_train = DataLoader(data, batch_size=batch_size, shuffle=False, drop_last=True, sampler=SequentialSampler(train_indices))\n",
    "dataloader_val = DataLoader(data, batch_size=batch_size, shuffle=False, drop_last=True, sampler=SequentialSampler(val_indices))\n",
    "dataloader_test = DataLoader(data, batch_size=batch_size, shuffle=False, drop_last=True, sampler=SequentialSampler(test_indices))\n",
    "\n",
    "print(\"\\nGenerated {:,} training batches of shape: {}\".format(len(dataloader_train), data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = data.seq_len*data.n_dim\n",
    "edge_features = data[0].num_edge_features  # 1 number * seq_len (skeleton connection for each edge for each timestep)\n",
    "node_embedding_dim = 64\n",
    "edge_embedding_dim = 32 # number of edge types\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "seq_len = 49\n",
    "predicted_timesteps = 0\n",
    "checkpoint_loaded = False \n",
    "\n",
    "model = VAE(node_features=node_features, \n",
    "            edge_features=edge_features, \n",
    "            hidden_size=hidden_size, \n",
    "            node_embedding_dim=node_embedding_dim,\n",
    "            edge_embedding_dim=edge_embedding_dim,\n",
    "            num_layers=num_layers,\n",
    "            input_size=node_embedding_dim, \n",
    "            output_size=node_features+predicted_timesteps*3,\n",
    "            sampling=False,\n",
    "            recurrent=True,\n",
    "           )\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=1e-4, weight_decay=5e-4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using {}\".format(device))\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(\"Total trainable parameters: {:,}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: load pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the whole model + weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"weights/seqlen3_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR load the model state into the pre-existing model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./logs/nooverlap_53joints_seqlen10_pred0/best_weights.pth\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_checkpoint = checkpoint['loss']\n",
    "checkpoint_loaded = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "prediction_to_reconstruction_loss_ratio = 0 # you might want to weight the prediction loss higher to help it compete with the larger prediction seq_len\n",
    "batch_limit = 1\n",
    "\n",
    "def train_model(epochs):\n",
    "    train_losses = []\n",
    "    train_reco_losses = []\n",
    "    train_pred_losses = []\n",
    "    val_losses = []\n",
    "    val_reco_losses = []\n",
    "    val_pred_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        t = time.time()\n",
    "        n_batches = 0\n",
    "        total_train_loss = 0\n",
    "        total_train_reco_loss = 0\n",
    "        total_train_pred_loss = 0\n",
    "        total_val_loss = 0\n",
    "        total_val_reco_loss = 0\n",
    "        total_val_pred_loss = 0\n",
    "        \n",
    "        ### TRAINING LOOP\n",
    "        for batch in dataloader_train:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            ### CALCULATE MODEL OUTPUTS\n",
    "            output = model(batch)\n",
    "            \n",
    "            ### CALCULATE LOSS\n",
    "            train_reco_loss = mse_loss(batch.x.to(device), output[:,:node_features]) # compare first seq_len timesteps.item()\n",
    "            if predicted_timesteps > 0: \n",
    "                train_pred_loss = prediction_to_reconstruction_loss_ratio*mse_loss(batch.y.to(device), output[:,node_features:]) # compare last part to unseen data\n",
    "                train_loss = train_reco_loss + train_pred_loss\n",
    "            else:\n",
    "                train_loss = train_reco_loss\n",
    "\n",
    "            ### ADD LOSSES TO TOTALS\n",
    "            total_train_loss += train_loss.item()\n",
    "            total_train_reco_loss += train_reco_loss.item()\n",
    "            if predicted_timesteps > 0: \n",
    "                total_train_pred_loss += train_pred_loss.item()\n",
    "\n",
    "            ### BACKPROPAGATE\n",
    "            optimizer.zero_grad() # reset the gradients to zero\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### OPTIONAL -- STOP TRAINING EARLY\n",
    "            n_batches += 1\n",
    "            if (batch_limit > 0) and (n_batches >= batch_limit): break # temporary -- for stopping training early\n",
    "        \n",
    "        ### VALIDATION LOOP\n",
    "        model.eval()\n",
    "        for batch in dataloader_val:\n",
    "            batch = batch.to(device)\n",
    "            \n",
    "            ### CALCULATE MODEL OUTPUTS\n",
    "            output = model(batch)\n",
    "            \n",
    "            ### CALCULATE LOSS\n",
    "            val_reco_loss = mse_loss(batch.x.to(device), output[:,:node_features]) # compare first seq_len timesteps.item()\n",
    "            if predicted_timesteps > 0: \n",
    "                val_pred_loss = prediction_to_reconstruction_loss_ratio*mse_loss(batch.y.to(device), output[:,node_features:]) # compare last part to unseen data\n",
    "                val_loss = val_reco_loss + val_pred_loss\n",
    "            else:\n",
    "                val_loss = val_reco_loss\n",
    "\n",
    "            ### ADD LOSSES TO TOTALS\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_reco_loss += val_reco_loss.item()\n",
    "            if predicted_timesteps > 0: \n",
    "                total_val_pred_loss += val_pred_loss.item()\n",
    "\n",
    "            ### OPTIONAL -- STOP TRAINING EARLY\n",
    "            n_batches += 1\n",
    "            if (batch_limit > 0) and (n_batches >= batch_limit): break # temporary -- for stopping training early\n",
    "        \n",
    "        ### CALCULATE AVERAGE LOSSES PER EPOCH   \n",
    "        epoch_train_loss = total_train_loss / n_batches\n",
    "        epoch_train_reco_loss = total_train_reco_loss / n_batches\n",
    "        epoch_train_pred_loss = total_train_pred_loss / n_batches\n",
    "\n",
    "        train_losses.append(epoch_train_loss) \n",
    "        train_reco_losses.append(epoch_train_reco_loss)\n",
    "        train_pred_losses.append(epoch_train_pred_loss)\n",
    "\n",
    "        epoch_val_loss = total_val_loss / n_batches\n",
    "        epoch_val_reco_loss = total_val_reco_loss / n_batches\n",
    "        epoch_val_pred_loss = total_val_pred_loss / n_batches\n",
    "\n",
    "        val_losses.append(epoch_val_loss) \n",
    "        val_reco_losses.append(epoch_val_reco_loss)\n",
    "        val_pred_losses.append(epoch_val_pred_loss)\n",
    "\n",
    "        print(\"epoch : {}/{} | train_loss = {:,.4f} | train_reco_loss: {:,.4f} | train_pred_loss: {:,.4f} | val_loss = {:,.4f} | val_reco_loss: {:,.4f} | val_pred_loss: {:,.4f} |time: {:.4f} sec\".format(epoch+1, epochs, \n",
    "                                                                                                                epoch_train_loss,\n",
    "                                                                                                                epoch_train_reco_loss, \n",
    "                                                                                                                epoch_train_pred_loss,\n",
    "                                                                                                                epoch_val_loss,\n",
    "                                                                                                                epoch_val_reco_loss, \n",
    "                                                                                                                epoch_val_pred_loss,\n",
    "                                                                                                                time.time() - t))\n",
    "        \n",
    "        if epoch == 0 and not checkpoint_loaded: best_loss = epoch_val_loss\n",
    "        elif epoch == 0 and checkpoint_loaded: best_loss = min(epoch_val_loss, loss_checkpoint)\n",
    "            \n",
    "        if epoch_val_loss < best_loss:\n",
    "            best_loss = epoch_val_loss\n",
    "#             torch.save({\n",
    "#              'epoch': epoch,\n",
    "#              'model_state_dict': model.state_dict(),\n",
    "#              'optimizer_state_dict': optimizer.state_dict(),\n",
    "#              'loss': best_loss,\n",
    "#              }, checkpoint_path)\n",
    "#             print(\"Better loss achieved -- saved model checkpoint to {}.\".format(checkpoint_path))\n",
    "\n",
    "    loss_dict = {\n",
    "\t\"train_losses\": train_losses,\n",
    "\t\"train_reco_losses\": train_reco_losses,\n",
    "\t\"train_pred_losses\": train_pred_losses,\n",
    "\t\"val_losses\": val_losses,\n",
    "\t\"val_reco_losses\": val_reco_losses,\n",
    "\t\"val_pred_losses\": val_pred_losses,\n",
    "\t\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./logs/vae_moreparams__53joints_seqlen49_pred0\"\n",
    "dataloader_test = torch.load(os.path.join(folder,\"dataloader_test.pth\"))\n",
    "checkpoint_path = os.path.join(folder,\"best_weights.pth\")\n",
    "dict = json.load(open(os.path.join(folder,\"losses.json\")))\n",
    "train_losses = dict['train_losses']\n",
    "val_losses = dict['val_losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_joints = 53\n",
    "seq_len = 49\n",
    "batch_size = 32\n",
    "predicted_timesteps = 0\n",
    "node_features = seq_len*3 # data.seq_len*data.n_dim\n",
    "edge_features = seq_len # data[0].num_edge_features\n",
    "node_embedding_dim = 40\n",
    "edge_embedding_dim = 4 # number of edge types\n",
    "hidden_size = 515\n",
    "num_layers = 4\n",
    "checkpoint_loaded = False \n",
    "\n",
    "model = VAE(node_features=node_features, \n",
    "            edge_features=edge_features, \n",
    "            hidden_size=hidden_size, \n",
    "            node_embedding_dim=node_embedding_dim,\n",
    "            edge_embedding_dim=edge_embedding_dim,\n",
    "            num_layers=num_layers,\n",
    "            input_size=node_embedding_dim, \n",
    "            output_size=node_features+predicted_timesteps*3,\n",
    "           )\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=1e-4, weight_decay=5e-4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using {}\".format(device))\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(\"Total trainable parameters: {:,}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_checkpoint = checkpoint['loss']\n",
    "checkpoint_loaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "    prediction_to_reconstruction_loss_ratio = 0\n",
    "    total_test_loss = 0\n",
    "    total_test_reco_loss = 0\n",
    "    total_test_pred_loss = 0\n",
    "    n_batches = 0\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader_test, desc=\"Test batches\"):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        ### CALCULATE MODEL OUTPUTS\n",
    "        output = model(batch)\n",
    "        \n",
    "        ### SAVE FOR ANIMATIONS\n",
    "        actuals.append(batch.x.detach().cpu().numpy())\n",
    "        preds.append(output.detach().cpu().numpy())\n",
    "\n",
    "        ### CALCULATE LOSS\n",
    "        test_reco_loss = mse_loss(batch.x.to(device), output[:,:node_features]) # compare first seq_len timesteps\n",
    "        if predicted_timesteps > 0: \n",
    "            test_pred_loss = prediction_to_reconstruction_loss_ratio*mse_loss(batch.y.to(device), output[:,node_features:]) # compare last part to unseen data\n",
    "            test_loss = test_reco_loss + test_pred_loss\n",
    "        else:\n",
    "            test_loss = test_reco_loss\n",
    "\n",
    "        ### ADD LOSSES TO TOTALS\n",
    "        total_test_loss += test_loss.item()\n",
    "        total_test_reco_loss += test_reco_loss.item()\n",
    "        if predicted_timesteps > 0: \n",
    "            total_test_pred_loss += test_pred_loss.item()\n",
    "        n_batches += 1\n",
    "        \n",
    "        if n_batches > 1: break ### OPTIONAL: STOP EARLY\n",
    "            \n",
    "    ### CALCULATE AVERAGE LOSSES PER EPOCH   \n",
    "    average_test_loss = total_test_loss / n_batches\n",
    "    average_test_reco_loss = total_test_reco_loss / n_batches\n",
    "    average_test_pred_loss = total_test_pred_loss / n_batches\n",
    "    print(\"Loss = {:,.4f} | Reconstruction Loss: {:,.4f} | Prediction Loss: {:,.4f}\".format(average_test_loss, \n",
    "                                                                                            average_test_reco_loss, \n",
    "                                                                                            average_test_pred_loss))\n",
    "    \n",
    "    return actuals, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals, preds = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_number = 0\n",
    "truth_sequences = []\n",
    "predicted_sequences = []\n",
    "\n",
    "for seq_number in np.arange(batch_size):\n",
    "    actual = actuals[batch_number][seq_number*n_joints:seq_number*n_joints+n_joints].reshape((n_joints,seq_len,3))\n",
    "    pred = preds[batch_number][seq_number*n_joints:seq_number*n_joints+n_joints].reshape((n_joints,seq_len,3))\n",
    "    actual = np.transpose(actual, [1,0,2])\n",
    "    pred = np.transpose(pred, [1,0,2])\n",
    "    truth_sequences.append(actual)\n",
    "    predicted_sequences.append(pred)\n",
    "    \n",
    "truth_sequences = np.asarray(truth_sequences).reshape((batch_size*seq_len, n_joints, 3))\n",
    "predicted_sequences = np.asarray(predicted_sequences).reshape((batch_size*seq_len, n_joints, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "# timesteps = seq_len*batch_size\n",
    "timesteps = 100\n",
    "animation = animate_stick(truth_sequences[start_index:start_index+timesteps,:,:], \n",
    "                          ghost=predicted_sequences[start_index:start_index+timesteps,:,:], \n",
    "                          ghost_shift=0.,\n",
    "                          ax_lims = (-0.7,0.7),\n",
    "                          figsize=(10,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses_moreparams = [1.2585,0.2413,0.2063,0.3304,0.1753,0.1665,0.1516,0.2043,0.1444,32.0709,0.1563,15.5246,0.7867,1.8139,2.1597,0.1700,0.1611,0.1606,0.1605,0.1671,0.1589,0.7795,0.1553,0.1550,0.1546,0.1544,0.1546,0.1546,0.1522,0.1533,0.1545,0.1509,0.1521,0.1538,0.1538,0.1467,0.1402,0.1433,0.1413,0.1402,0.1425,0.1419,0.1372,0.1359,0.1319,0.1331,0.1354,0.1371,0.1360,0.1283,0.1283,0.1277,0.1277,0.1271,0.1353,0.1353,0.1390,0.1249,0.0118,0.0040,0.1584,0.1568,0.1558,0.1556,0.1556,0.1554,0.1536,0.1535,0.1533,0.1523,0.1419,0.1338,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "# ax.plot(np.arange(len(nooverlap_val_losses)), nooverlap_val_losses, label=\"Validation (No Overlap)\")\n",
    "ax.plot(np.arange(len(val_losses)), val_losses, label=\"Graph VAE (250k params)\")\n",
    "ax.plot(np.arange(len(val_losses_moreparams)), val_losses_moreparams, label=\"Graph VAE (1.8M params)\")\n",
    "ax.set_xlabel(\"Epoch\", fontsize=16)\n",
    "ax.set_ylabel(\"Validation Reco Loss\", fontsize=16)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_ylim(-0.1,0.5)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "ax.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up next:\n",
    "- Try to overfit the input data (loss = 0) by setting prediction weight = 0\n",
    "- Weight the prediction loss to ensure that the most immediate steps are more important to reconstruct than far future steps (like 1/2^t or something)\n",
    "\n",
    "### For later:\n",
    "- The Gaussian negative log likelihood loss functions will only make sense when the output of the decoder is mu (eq'n 16 & 17)\n",
    "\n",
    "### Done\n",
    "- ~~Predict 50 + k timesteps w/ separate MSE losses~~\n",
    "- ~~Look at VAE outputs!~~\n",
    "- ~~Look at NRI outputs!~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             my_nll_loss = gaussian_neg_log_likelihood(x=batch.x, mu=output, sigma=sigma)\n",
    "#             nll_loss = nll_gaussian(preds=output, target=batch.x.to(device), variance=5e-5)\n",
    "#             kl_loss = kl_categorical_uniform(torch.exp(log_probabilities), data[0].num_nodes, num_edge_types, add_const=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_index = 0\n",
    "# timesteps = seq_len\n",
    "# animation = animate_stick(actual[start_index:start_index+timesteps,:,:], \n",
    "#                           ghost=pred[start_index:start_index+timesteps,:,:], \n",
    "#                           ghost_shift=0.4,\n",
    "#                           ax_lims = (-0.7,0.7),\n",
    "#                           figsize=(10,8), cmap='inferno')\n",
    "# HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
