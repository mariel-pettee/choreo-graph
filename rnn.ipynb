{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pca = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functions.functions import *\n",
    "from functions.plotting import *\n",
    "from functions.autoencoder import *\n",
    "from functions.mdn import *\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "import livelossplot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from itertools import combinations\n",
    "import matplotlib\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/project/hep/demers/mnp3/miniconda3/envs/choreo/bin/ffmpeg' # for using html5 video in Jupyter notebook\n",
    "print(matplotlib.animation.writers.list()) # check that ffmpeg is loaded. if it's not there, use .to_jshtml() instead of .to_html5_video()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('rnn_data/mariel_*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.random.randint(0,data.full.X.shape[1]-50)\n",
    "print(\"Starting from frame {}...\".format(frame))\n",
    "\n",
    "# HTML(animate(data.full.X[:,frame:,:], frames=100))\n",
    "HTML(animate(data.selected.X[:,frame:,:], frames=100, edges=data.selected.edges, colors='black'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM + MDN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data with x,y centering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = np.random.randint(0,data.full.X.shape[1]-50)\n",
    "X = data.selected.X # 15 joints\n",
    "X = X.swapaxes(0, 1)\n",
    "X[:,:,0] = X[:,:,0] - np.mean(X[:,:,0], axis=0) + 0.5*np.ones(15)\n",
    "X[:,:,1] = X[:,:,1] - np.mean(X[:,:,1], axis=0) + 0.5*np.ones(15)\n",
    "HTML(animate(data.selected.X[:,frame:,:], frames=100, edges=data.selected.edges, colors='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pca: \n",
    "    X = data.selected.X # 15 joints\n",
    "    # Average frame-by-frame in (x,y):\n",
    "    X = X.swapaxes(0, 1)\n",
    "    X[:,:,0] = X[:,:,0] - np.mean(X[:,:,0], axis=0) + 0.5*np.ones(15)\n",
    "    X[:,:,1] = X[:,:,1] - np.mean(X[:,:,1], axis=0) + 0.5*np.ones(15)\n",
    "    X = X.reshape(X.shape[0],X.shape[1]*X.shape[2])\n",
    "\n",
    "    # PCA time:\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(.95)\n",
    "    pca_reduced_data = pca.fit_transform(X)\n",
    "    print('PCA reduction to a {}-dimensional latent space.'.format(pca_reduced_data.shape[1]))\n",
    "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "    print(pca_reduced_data.shape)\n",
    "    n_time, n_dims, n_verts  = pca_reduced_data.shape[0], 1, pca_reduced_data.shape[1]\n",
    "    n_mixes = 6\n",
    "    look_back = 128\n",
    "\n",
    "    lstm_mdn = LSTM_MDN(cells = [512,512,512,512], n_verts=n_verts, n_dims=n_dims, n_mixes=n_mixes, look_back=look_back)\n",
    "\n",
    "    train_X = []\n",
    "    train_Y = []\n",
    "    for i in range(look_back, n_time, 1):\n",
    "        train_X.append( pca_reduced_data[i-look_back:i,:] ) # look_back, verts * dims\n",
    "        train_Y.append( pca_reduced_data[i,:] ) # verts * dims\n",
    "    train_X = np.array(train_X) # n_samples, lookback, verts * dims\n",
    "    train_Y = np.array(train_Y) # n_samples, verts * dims\n",
    "    \n",
    "    print(train_X.shape, train_Y.shape)\n",
    "    lstm_mdn.model.summary()\n",
    "    \n",
    "else:\n",
    "    X = data.selected.X # 15 joints\n",
    "    n_verts, n_time, n_dims = X.shape\n",
    "    n_mixes = 3\n",
    "    look_back = 10\n",
    "\n",
    "    lstm_mdn = LSTM_MDN(cells = [10,10,10,10], n_verts=n_verts, n_dims=n_dims, n_mixes=n_mixes, look_back=look_back)\n",
    "    train_X, train_Y = lstm_mdn.prepare_inputs(X, look_back=look_back)\n",
    "    print(train_X.shape)\n",
    "    print(train_Y.shape)\n",
    "    lstm_mdn.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath=\"weights/weights-lstm_pca_test.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model:\n",
    "lstm_mdn.model.fit(train_X, train_Y, \n",
    "                   epochs=100, \n",
    "                   batch_size=128, \n",
    "                   shuffle=False, \n",
    "                   verbose=1,\n",
    "                   callbacks=[checkpoint, TerminateOnNaN()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = lstm_mdn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a trained model + weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model_from_json(open('models/model-32chor-rnn.json').read(), {'MDN': MDN, 'LSTM_MDN': LSTM_MDN})\n",
    "trained_model.load_weights('weights/weights-32chor-rnn.h5')\n",
    "trained_model.summary()\n",
    "\n",
    "n_mixes = 6\n",
    "look_back = 128\n",
    "\n",
    "if use_pca:\n",
    "    means = np.load('pca/rnn_pca_32-means.npy')\n",
    "    components = np.load('pca/rnn_pca_32-components.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well the model can predict the next frame in the input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize how well the model learned the input sequence\n",
    "n_frames = 100 # n frames of time slices to generate\n",
    "output_dims = train_X.shape[2]\n",
    "frame = np.random.randint(0,data.full.X.shape[1]-50)\n",
    "print(\"Seeding with frame {}\".format(frame))\n",
    "frames = []\n",
    "\n",
    "test_X = train_X[frame:frame+n_frames] # data to pass into forward prop through the model\n",
    "y_pred = trained_model.model.predict(test_X) # output with shape (n_frames, (output_dims+2) * n_mixes )\n",
    "\n",
    "# partition out the mus, sigs, and mixture weights\n",
    "for i in range(n_frames):\n",
    "    y = y_pred[i].squeeze()\n",
    "    mus = y[:n_mixes*output_dims]\n",
    "    sigs = y[n_mixes*output_dims:n_mixes*output_dims + n_mixes]\n",
    "    alphas = y[-n_mixes:]\n",
    "    # find the most likely distribution - then disregard that number and use the first Gaussian :)\n",
    "    alpha_idx = np.argmax(alphas)\n",
    "    alpha_idx = 0\n",
    "    # pull out the mus that correspond to the selected alpha index\n",
    "    positions = mus[alpha_idx * output_dims:(alpha_idx+1) * output_dims]\n",
    "    frames.append(positions)\n",
    "\n",
    "if use_pca:\n",
    "    # With PCA:\n",
    "    frames = np.dot(frames, components) + means\n",
    "    print(frames.shape)\n",
    "    lstm_predictions = frames.swapaxes(0,1)\n",
    "    lstm_predictions = np.dstack((lstm_predictions[::3,:],lstm_predictions[1::3,:],lstm_predictions[2::3,:]))\n",
    "else:\n",
    "    # No PCA:\n",
    "    frames = np.array(frames)\n",
    "    lstm_predictions = np.dstack((frames.T[::3,:],frames.T[1::3,:],frames.T[2::3,:]))\n",
    "    \n",
    "HTML(animate_ghost(data.selected.X[:,frame:,:], lstm_predictions[:,:,:], frames=n_frames, edges=data.selected.edges, colors='blue', ghost_shift = 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now generate new sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 128 # n frames of time slices to generate\n",
    "frames = []\n",
    "seed = np.random.randint(0, len(train_X)-1)\n",
    "x = np.expand_dims(train_X[seed], axis=0)\n",
    "print(' * seeding with', seed)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    y = trained_model.model.predict(x).squeeze()\n",
    "    mus = y[:n_mixes*output_dims]\n",
    "    sigs = y[n_mixes*output_dims:-n_mixes]\n",
    "    alphas = softmax(y[-n_mixes:])\n",
    "\n",
    "    # select the alpha channel to use\n",
    "    alpha_idx = np.argmax(alphas)\n",
    "\n",
    "    # grab the mus and sigs associated with the selected alpha_idx\n",
    "    frame_mus = mus.ravel()[alpha_idx*output_dims : (alpha_idx+1)*output_dims]\n",
    "    frame_sig = sigs[alpha_idx] / 100\n",
    "\n",
    "    # now sample from each Gaussian\n",
    "    positions = [np.random.normal(loc=m, scale=frame_sig) for m in frame_mus]\n",
    "    positions = frame_mus\n",
    "\n",
    "    # add these positions to the results\n",
    "    frames.append(positions)\n",
    "\n",
    "    # pull out a new training example - stack the new result on\n",
    "    # all values after the first from the bottom-most value in the x's\n",
    "    start = x[:,1:,:]\n",
    "    end = np.expand_dims( np.expand_dims(positions, axis=0), axis=0 )\n",
    "    x = np.concatenate((start, end), axis=1)\n",
    "    \n",
    "frames = np.array(frames)\n",
    "\n",
    "if use_pca:\n",
    "    # With PCA:\n",
    "    frames = np.dot(frames, components) + means\n",
    "#     print(frames.shape)\n",
    "    lstm_predictions = frames.swapaxes(0,1)\n",
    "    lstm_predictions = np.dstack((lstm_predictions[::3,:],lstm_predictions[1::3,:],lstm_predictions[2::3,:]))\n",
    "else:\n",
    "    # No PCA:\n",
    "    lstm_predictions = np.dstack((frames.T[::3,:],frames.T[1::3,:],frames.T[2::3,:]))\n",
    "    \n",
    "prompt_plus_generated_seq = np.concatenate((data.selected.X[:,seed:seed+look_back,:],lstm_predictions), axis=1)\n",
    "HTML(animate_ghost(data.selected.X[:,seed:seed+look_back+n_frames:,:], prompt_plus_generated_seq, frames=look_back+n_frames, edges=data.selected.edges, colors='blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animate(lstm_predictions, frames=n_frames, edges=data.selected.edges, colors='blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo2020",
   "language": "python",
   "name": "choreo2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
