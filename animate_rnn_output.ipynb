{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functions.functions import *\n",
    "from functions.plotting import *\n",
    "from functions.autoencoder import *\n",
    "from functions.mdn import *\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TerminateOnNaN, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "import livelossplot\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from itertools import combinations\n",
    "import matplotlib\n",
    "plt.rcParams['animation.ffmpeg_path'] = '/gpfs/loomis/project/hep/demers/mnp3/conda_envs/choreo/bin/ffmpeg' # for using html5 video in Jupyter notebook\n",
    "print(matplotlib.animation.writers.list()) # check that ffmpeg is loaded. if it's not there, use .to_jshtml() instead of .to_html5_video()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('data/mariel_*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the real data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame = np.random.randint(0,data.selected.X.shape[1]-50)\n",
    "print(\"Starting from frame {}...\".format(frame))\n",
    "\n",
    "# HTML(animate(data.full.X[:,frame:,:], frames=100))\n",
    "HTML(animate(data.selected.X[:,frame:,:], frames=100, edges=data.selected.edges, colors='black'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for the LSTM_MDN\n",
    "X = data.selected.X\n",
    "X.shape\n",
    "X = X.swapaxes(0, 1) # reshape to time, vert, dim\n",
    "n_time, n_verts, n_dims = X.shape\n",
    "look_back = 128\n",
    "n_mixes = 6\n",
    "\n",
    "# center each frame along the x and y axes to simplify training\n",
    "X[:,:,0] = X[:,:,0] - np.mean(X[:,:,0], axis=0) + 0.5*np.ones(n_verts)\n",
    "X[:,:,1] = X[:,:,1] - np.mean(X[:,:,1], axis=0) + 0.5*np.ones(n_verts)\n",
    "\n",
    "# lstm expects data in shape [samples_in_batch, timestamps, values]\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for i in range(look_back, n_time, 1):\n",
    "    train_X.append( X[i-look_back:i,:,:].reshape(look_back, n_verts * n_dims) ) # look_back, verts * dims\n",
    "    train_Y.append( X[i,:,:].reshape(n_verts * n_dims) ) # verts * dims\n",
    "train_X = np.array(train_X) # n_samples, lookback, verts * dims\n",
    "train_Y = np.array(train_Y) # n_samples, verts * dims\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained model + weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model_from_json(open('models/model-32chor-rnn.json').read(), {'MDN': MDN, 'LSTM_MDN': LSTM_MDN})\n",
    "trained_model.load_weights('weights/weights-32chor-rnn.h5')\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how well the model can predict the next frame in the input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize how well the model learned the input sequence\n",
    "n_frames = 100 # n frames of time slices to generate\n",
    "output_dims = train_X.shape[2]\n",
    "frame = np.random.randint(0,data.full.X.shape[1]-50)\n",
    "frames = []\n",
    "\n",
    "test_X = train_X[frame:frame+n_frames] # data to pass into forward prop through the model\n",
    "y_pred = trained_model.predict(test_X) # output with shape (n_frames, (output_dims+2) * n_mixes )\n",
    "\n",
    "# partition out the mus, sigs, and mixture weights\n",
    "for i in range(n_frames):\n",
    "    y = y_pred[i].squeeze()\n",
    "    mus = y[:n_mixes*output_dims]\n",
    "    sigs = y[n_mixes*output_dims:n_mixes*output_dims + n_mixes]\n",
    "    alphas = y[-n_mixes:]\n",
    "    # find the most likely distribution\n",
    "    alpha_idx = np.argmax(alphas)\n",
    "    # pull out the mus that correspond to the selected alpha index\n",
    "    positions = mus[alpha_idx * output_dims:(alpha_idx+1) * output_dims]\n",
    "    frames.append(positions)\n",
    "#     print(alphas)\n",
    "frames = np.array(frames)\n",
    "lstm_predictions = np.dstack((frames.T[::3,:],frames.T[1::3,:],frames.T[2::3,:]))\n",
    "HTML(animate_ghost(data.selected.X[:,frame:,:], lstm_predictions, frames=n_frames, edges=data.selected.edges, colors='blue', ghost_shift = 0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now generate new sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 100 # n frames of time slices to generate\n",
    "frames = []\n",
    "seed = np.random.randint(0, len(train_X)-1)\n",
    "x = np.expand_dims(train_X[seed], axis=0)\n",
    "print(' * seeding with', seed)\n",
    "\n",
    "for i in range(n_frames):\n",
    "    y = trained_model.predict(x).squeeze()\n",
    "    mus = y[:n_mixes*output_dims]\n",
    "    sigs = y[n_mixes*output_dims:-n_mixes]\n",
    "    alphas = softmax(y[-n_mixes:])\n",
    "\n",
    "    # select the alpha channel to use\n",
    "    alpha_idx = np.argmax(alphas)\n",
    "#     print(alphas)\n",
    "    # grab the mus and sigs associated with the selected alpha_idx\n",
    "    frame_mus = mus.ravel()[alpha_idx*output_dims : (alpha_idx+1)*output_dims]\n",
    "    frame_sig = sigs[alpha_idx] / 100\n",
    "\n",
    "    # now sample from each Gaussian\n",
    "    positions = [np.random.normal(loc=m, scale=frame_sig) for m in frame_mus]\n",
    "    positions = frame_mus\n",
    "\n",
    "    # add these positions to the results\n",
    "    frames.append(positions)\n",
    "\n",
    "    # pull out a new training example - stack the new result on\n",
    "    # all values after the first from the bottom-most value in the x's\n",
    "    start = x[:,1:,:]\n",
    "    end = np.expand_dims( np.expand_dims(positions, axis=0), axis=0 )\n",
    "    x = np.concatenate((start, end), axis=1)\n",
    "    \n",
    "frames = np.array(frames)\n",
    "lstm_predictions = np.dstack((frames.T[::3,:],frames.T[1::3,:],frames.T[2::3,:]))\n",
    "prompt_plus_generated_seq = np.concatenate((data.selected.X[:,seed:seed+look_back,:],lstm_predictions), axis=1)\n",
    "HTML(animate_ghost(data.selected.X[:,seed:seed+look_back+n_frames:,:], prompt_plus_generated_seq, frames=look_back+n_frames, edges=data.selected.edges, colors='blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animate(lstm_predictions, frames=n_frames, edges=data.selected.edges, colors='blue'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choreo",
   "language": "python",
   "name": "choreo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
