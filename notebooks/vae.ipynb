{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions.load_data import MarielDataset, edges\n",
    "from functions.functions import *\n",
    "from functions.modules import *\n",
    "from functions.plotting import *\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, SubsetRandomSampler, SequentialSampler\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import networkx as nx # for visualizing graphs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import json\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -latrh ../logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../logs/fulltraining_lr1e-6_sparsity\"\n",
    "dataloader_test = torch.load(os.path.join(folder,\"dataloader_test.pth\")) ## override with my longer dataset loader\n",
    "checkpoint_path = os.path.join(folder,\"best_weights.pth\")\n",
    "args_file = os.path.join(folder, 'args.pkl')\n",
    "args = pickle.load(open(args_file, \"rb\" ))['args']\n",
    "checkpoint_loaded = False \n",
    "print(args)\n",
    "\n",
    "# Load these if training actually completed:\n",
    "if os.path.exists(os.path.join(folder,\"losses.json\")):\n",
    "    dict = json.load(open(os.path.join(folder,\"losses.json\")))\n",
    "    train_losses = dict['train_losses']\n",
    "    val_losses = dict['val_losses']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.plot(np.arange(len(train_losses)), train_losses, label=\"Training\")\n",
    "    ax.plot(np.arange(len(val_losses)), val_losses, label=\"Validation\")\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=16)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=16)\n",
    "#     ax.set_yscale(\"log\")\n",
    "#     ax.set_ylim(-0.05,20)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax.legend(fontsize=14)\n",
    "    plt.savefig(os.path.join(folder,\"loss_curve.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() and args.no_cuda == False:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "model = NRI(device=device,\n",
    "            node_features=args.seq_len*6, \n",
    "            edge_features=args.seq_len, \n",
    "            hidden_size=args.hidden_size, \n",
    "            node_embedding_dim=args.node_embedding_dim,\n",
    "            edge_embedding_dim=args.edge_embedding_dim,\n",
    "            skip_connection=args.skip_connection,\n",
    "            dynamic_graph=False,\n",
    "            seq_len=args.seq_len,\n",
    "            predicted_timesteps=args.predicted_timesteps,\n",
    "            ablation_edge_index=3,\n",
    "            threshold=50, # use top (100-x)% of edges\n",
    "           )\n",
    "\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=args.lr, weight_decay=5e-4)\n",
    "\n",
    "print(\"Using {}\".format(device))\n",
    "model = model.to(device)\n",
    "# print(model)\n",
    "print(\"Total trainable parameters: {:,}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss_checkpoint = checkpoint['loss']\n",
    "checkpoint_loaded = True\n",
    "n_joints = 53\n",
    "print(loss_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(batch_limit=0):\n",
    "    mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "    prediction_to_reconstruction_loss_ratio = 1 # CHANGE THIS TO ARGS\n",
    "    total_test_loss = 0\n",
    "    n_batches = 0\n",
    "    actuals = []\n",
    "    preds = []\n",
    "    edge_types_list = []\n",
    "    logits_list = []\n",
    "    probabilities_list = []\n",
    "    model.eval()\n",
    "    \n",
    "    for batch in tqdm(dataloader_test, desc=\"Test batches\"):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        ### CALCULATE MODEL OUTPUTS\n",
    "        output, edge_types, logits, edges = model(batch)\n",
    "        \n",
    "        ### SAVE FOR ANIMATIONS\n",
    "        actuals.append(batch.x.detach().cpu().numpy())\n",
    "        preds.append(output.detach().cpu().numpy())\n",
    "        logits_list.append(logits.detach().cpu().numpy())\n",
    "        edge_types_list.append(edge_types.detach().cpu().numpy())\n",
    "        probabilities_list.append(edges.detach().cpu().numpy())\n",
    "\n",
    "        ### CALCULATE LOSS\n",
    "        test_loss = mse_loss(batch.x.to(device), output) # compare first seq_len timesteps\n",
    "\n",
    "        ### ADD LOSSES TO TOTALS\n",
    "        total_test_loss += test_loss.item()\n",
    "            \n",
    "        ### OPTIONAL -- STOP TESTING EARLY\n",
    "        n_batches += 1\n",
    "        if (batch_limit > 0) and (n_batches >= batch_limit): break # temporary -- for stopping training early\n",
    "\n",
    "    ### CALCULATE AVERAGE LOSSES PER EPOCH   \n",
    "    average_test_loss = total_test_loss / n_batches\n",
    "    print(\"Loss = {:,.8f}\".format(average_test_loss))\n",
    "    return actuals, preds, edge_types_list, logits_list, probabilities_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals, preds, edge_types, logits, probs = test(batch_limit = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANIMATE A SINGLE BATCH ONLY \n",
    "batch_number = 9\n",
    "truth_sequences= []\n",
    "predicted_sequences = []\n",
    "\n",
    "for seq_number in np.arange(args.batch_size):\n",
    "    actual = actuals[batch_number][seq_number*n_joints:seq_number*n_joints+n_joints].reshape((n_joints,args.seq_len,6))[:,:,:3] # take the first 3 dimensions for positions, not velocities\n",
    "    pred = preds[batch_number][seq_number*n_joints:seq_number*n_joints+n_joints].reshape((n_joints,args.seq_len,6))[:,:,:3]\n",
    "    actual = np.transpose(actual, [1,0,2])\n",
    "    pred = np.transpose(pred, [1,0,2])\n",
    "    truth_sequences.append(actual)\n",
    "    predicted_sequences.append(pred)\n",
    "    \n",
    "truth_sequences = np.asarray(truth_sequences).reshape((args.batch_size*args.seq_len, n_joints, 3))\n",
    "predicted_sequences = np.asarray(predicted_sequences).reshape((args.batch_size*args.seq_len, n_joints, 3))\n",
    "\n",
    "start_index = 0\n",
    "# timesteps = args.seq_len*args.batch_size\n",
    "timesteps = args.seq_len\n",
    "animation = animate_stick(truth_sequences[start_index:start_index+timesteps,:,:], \n",
    "                          ghost=predicted_sequences[start_index:start_index+timesteps,:,:], \n",
    "                          ghost_shift=0.4,\n",
    "                          ax_lims = (-0.7,0.3),\n",
    "                          skeleton=True,\n",
    "                          skeleton_alpha=1,\n",
    "                          figsize=(10,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same thing, but with edge types..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = edge_types[0] # one-hot encoded edges\n",
    "logits = logits[0] # unnormalized log-probabilities\n",
    "probs = probs[0] # normalized logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(edge_types, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of the edges that belong to each class\n",
    "percentages = edge_types.sum(axis=0)/edge_types.shape[0]\n",
    "\n",
    "for i in range(len(percentages)):\n",
    "    print(\"Edge type {}: {:.1f}%\".format(i, percentages[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "bins = np.linspace(0.,1,100)\n",
    "for i in range(4):\n",
    "    ax.hist(probs[:,i],bins=bins, label=\"Edge type \"+str(i), histtype=\"step\", linewidth=3)\n",
    "ax.legend(fontsize=15, loc=\"best\")\n",
    "ax.set_title(\"Edge Type Probabilities (Normalized)\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_class = 0\n",
    "threshold = np.percentile(probs[:,edge_class],98) # top 1% of edges if the threshold is 99\n",
    "print(threshold)\n",
    "timesteps=1\n",
    "animation = animate_stick(truth_sequences[start_index:start_index+timesteps,:,:], \n",
    "#                           ghost=predicted_sequences[start_index:start_index+timesteps,:,:], \n",
    "#                           ghost_shift=0.4,\n",
    "                          cloud=True,\n",
    "                          cloud_alpha=0.003, # default=0.03 or 0.1\n",
    "                          edge_types=edge_types,\n",
    "                          edge_opacities=probs, \n",
    "                          threshold=threshold, # only plot the edges above this threshold with opacities given by scaled argmax\n",
    "                          edge_class = edge_class,\n",
    "                          skeleton = True,\n",
    "                          ax_lims = (-0.5,0.5),\n",
    "                          figsize=(10,8), \n",
    "                          cmap='Greys',\n",
    "                         )\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test w/ predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq_len = 100\n",
    "data = MarielDataset(seq_len=test_seq_len, \n",
    "                     reduced_joints=False, \n",
    "                     predicted_timesteps=100-args.seq_len, \n",
    "                     no_overlap=True, \n",
    "                     file_path=\"../data/mariel_*.npy\")\n",
    "test_indices = np.arange(int(0.85*len(data)), len(data)) # last 15% on test\n",
    "test = torch.utils.data.Subset(data, test_indices)\n",
    "dataloader_test_long = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pred(batch_limit=0):\n",
    "    mse_loss = torch.nn.MSELoss(reduction='mean')\n",
    "    total_test_loss = 0\n",
    "    n_batches = 0\n",
    "    actuals_all = []\n",
    "    preds_all = []\n",
    "    preds_all_for_animation = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(dataloader_test_long, desc=\"Test batches\"):\n",
    "        actuals = []\n",
    "        preds = []\n",
    "        preds_for_animation = []\n",
    "        batch = batch.to(device)\n",
    "        for i in range(test_seq_len):\n",
    "            if i == 0 :\n",
    "                x = batch.x[:,:args.seq_len*6]\n",
    "                input_seq = Data(x=x, edge_index=batch.edge_index, edge_attr=batch.edge_attr)\n",
    "            elif i == 1: \n",
    "                preds_for_animation.append(preds[i-1]) # start out the animation of predictions with the real steps + first predictions\n",
    "                x_real = batch.x[:,:(args.seq_len-args.predicted_timesteps)*6]\n",
    "                x_pred = torch.tensor(preds[i-1][:,-args.predicted_timesteps*6:]).to(device) # add on the previous sequence's predictions\n",
    "                x = torch.cat([x_real, x_pred], axis=1)\n",
    "                input_seq = Data(x=x, edge_index=batch.edge_index, edge_attr=batch.edge_attr)\n",
    "                preds_for_animation.append(x_pred.detach().cpu().numpy())\n",
    "            elif i*args.predicted_timesteps < args.seq_len:\n",
    "                x_real = batch.x[:,:(args.seq_len-i*args.predicted_timesteps)*6]\n",
    "                new_pred = torch.tensor(preds[i-1][:,-args.predicted_timesteps*6:]).to(device)\n",
    "                x_pred = torch.cat([x_pred, new_pred], axis=1) # add on the previous sequence's predictions\n",
    "                x = torch.cat([x_real, x_pred], axis=1)\n",
    "                input_seq = Data(x=x, edge_index=batch.edge_index, edge_attr=batch.edge_attr)\n",
    "                preds_for_animation.append(new_pred.detach().cpu().numpy())\n",
    "            elif i*args.predicted_timesteps >= args.seq_len:\n",
    "                x = torch.tensor(preds[i-1]).to(device) # now this is the right size to feed into the model\n",
    "                input_seq = Data(x=x, edge_index=batch.edge_index, edge_attr=batch.edge_attr)\n",
    "                new_pred = torch.tensor(preds[i-1][:,-args.predicted_timesteps*6:]).to(device)\n",
    "                preds_for_animation.append(new_pred.detach().cpu().numpy())\n",
    "                \n",
    "            ### CALCULATE MODEL OUTPUTS\n",
    "            output, edge_types, logits, edges = model(input_seq)\n",
    "\n",
    "            ## CALCULATE LOSS\n",
    "            test_loss = mse_loss(input_seq.x, output) # compare first seq_len timesteps\n",
    "    \n",
    "            ### SAVE FOR ANIMATIONS  \n",
    "            preds.append(output.detach().cpu().numpy())\n",
    "    \n",
    "        ### STACK\n",
    "        actuals_all.append(batch.x.detach().cpu().numpy())\n",
    "        preds_all.append(np.hstack(preds))\n",
    "        preds_all_for_animation.append(np.hstack(preds_for_animation))\n",
    "        \n",
    "        ### ADD LOSSES TO TOTALS\n",
    "        total_test_loss += test_loss.item()\n",
    "            \n",
    "        ### OPTIONAL -- STOP TESTING EARLY\n",
    "        n_batches += 1\n",
    "        if (batch_limit > 0) and (n_batches >= batch_limit): break # temporary -- for stopping training early\n",
    "\n",
    "    ### CALCULATE AVERAGE LOSSES PER EPOCH   \n",
    "    average_test_loss = total_test_loss / n_batches\n",
    "    print(\"Loss = {:,.8f}\".format(average_test_loss))\n",
    "    return actuals_all, preds_all, preds_all_for_animation, test_seq_len, n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals, preds, preds_animation, test_seq_len, n_batches = test_pred(batch_limit = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANIMATE A SINGLE BATCH ONLY \n",
    "batch_number = 0\n",
    "truth_sequences= []\n",
    "predicted_sequences = []\n",
    "\n",
    "pred_steps = int(preds_animation[0].shape[1]/6)\n",
    "\n",
    "actual = actuals[batch_number].reshape((n_joints,test_seq_len,6))[:,:,:3] # take the first 3 dimensions for positions, not velocities\n",
    "pred = preds_animation[batch_number].reshape((n_joints,pred_steps,6))[:,:,:3]\n",
    "actual = np.transpose(actual, [1,0,2])\n",
    "pred = np.transpose(pred, [1,0,2])\n",
    "truth_sequences.append(actual)\n",
    "predicted_sequences.append(pred)\n",
    "    \n",
    "truth_sequences = np.asarray(truth_sequences).reshape((test_seq_len, n_joints, 3))\n",
    "predicted_sequences = np.asarray(predicted_sequences).reshape((pred_steps, n_joints, 3))\n",
    "\n",
    "# timesteps = args.seq_len*args.batch_size\n",
    "timesteps = pred_steps\n",
    "animation = animate_stick(truth_sequences[:timesteps,:,:], \n",
    "                          ghost=predicted_sequences[:timesteps,:,:], \n",
    "                          ghost_shift=0.4,\n",
    "                          ax_lims = (-0.7,0.3),\n",
    "                          skeleton=True,\n",
    "                          skeleton_alpha=1,\n",
    "                          figsize=(10,8), cmap='inferno')\n",
    "HTML(animation.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq0 = [0.00005295,0.00260335,0.00151683,0.00099490,0.00178975]\n",
    "avg = [0.00006506,0.00261071,0.00157890,0.00101111,0.00178699]\n",
    "\n",
    "labels = [\"All edge types\", \"Only Type 0\", \"Only Type 1\", \"Only Type 2\", \"Only Type 3\"]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "bins = np.linspace(0.,1,100)\n",
    "\n",
    "rects1 = ax.bar(x - width/2, seq0, width, label=\"One test sequence\")\n",
    "rects2 = ax.bar(x + width/2, avg, width, label=\"Average of 25 test sequences\")\n",
    "\n",
    "# ax.set_ylabel('MSE')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=0)\n",
    "ax.legend(fontsize=15, loc=\"best\")\n",
    "ax.set_title(\"Reconstruction Loss (MSE)\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq0 = [0.00006674,0.00024483,0.00020931,0.00016127,0.00013859]\n",
    "\n",
    "\n",
    "labels = [\"All edge types\", \"Only Type 0\", \"Only Type 1\", \"Only Type 2\", \"Only Type 3\"]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "bins = np.linspace(0.,1,100)\n",
    "\n",
    "rects1 = ax.bar(x, seq0, width, label=\"One test sequence\")\n",
    "\n",
    "# ax.set_ylabel('MSE')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=0)\n",
    "ax.legend(fontsize=15, loc=\"best\")\n",
    "ax.set_title(\"Reconstruction Loss (MSE)\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq0 = [0.00015296,0.00063390,0.00037075,0.00053506,0.00045124]\n",
    "top1percent = [0.00060024,0.00063390,0.00061622,0.00062297,0.00062868]\n",
    "top50percent = [0.00016835,0.00063390,0.00037819,0.00054157,0.00046595]\n",
    "labels = [\"All edge types\", \"Only Type 0\", \"Only Type 1\", \"Only Type 2\", \"Only Type 3\"]\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "bins = np.linspace(0.,1,100)\n",
    "\n",
    "ax.bar(x - width, seq0, width, label=\"One test sequence\")\n",
    "ax.bar(x, top50percent, width, label=\"Top 50% of Edges\")\n",
    "ax.bar(x + width, top1percent, width, label=\"Top 1% of Edges\")\n",
    "\n",
    "# ax.set_ylabel('MSE')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=0)\n",
    "ax.legend(fontsize=15, loc=\"best\")\n",
    "ax.set_title(\"Reconstruction Loss (MSE)\", fontsize=20)\n",
    "ax.tick_params(axis='both', which='major', labelsize=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_geo",
   "language": "python",
   "name": "pytorch_geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
